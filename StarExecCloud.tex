\documentclass{easychair}

% \usepackage{doc}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage[straightquotes]{newtxtt}

%----Suppress extra space in texttt mode
\AddToHook{cmd/ttfamily/after}{\frenchspacing}

%----Making things more compact
\newcommand{\smalltt}[1]{\small \texttt{#1}}
\newenvironment{packed_itemize}{
\vspace*{-0.3em}
\begin{itemize}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{itemize}}
\newenvironment{packed_enumerate}{
\vspace*{-0.3em}
\begin{enumerate}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{enumerate}}
% \renewcommand{\textfraction}{0.07}
% \renewcommand{\topfraction}{0.9}
% \renewcommand{\bottomfraction}{0.9}
% \renewcommand{\floatpagefraction}{0.66}
% \setlength{\floatsep}{2.0pt plus 2.0pt minus 2.0pt}
% \setlength{\textfloatsep}{5.0pt plus 2.0pt minus 0.0pt}

\newcommand{\alex}[1]{{\color{red}{{#1}}}}

\title{Towards StarExec in the Cloud}

\author{
  David Fuenmayor\inst{1}
\and
  Jack McKeown\inst{2}
\and
  Geoff Sutcliffe\inst{2}
}

\institute{
  University of Bamberg,
  Bamberg, Germany\\
  \email{david.fuenmayor@uni-bamberg.de}
\and
  University of Miami,
  Miami, USA\\
  \email{jam771@miami.edu,geoff@cs.miami.edu}
}

\authorrunning{Fuenmayor, McKeown, Sutcliffe}
\titlerunning{Stars in the Clouds}

\begin{document}
\maketitle

%--------------------------------------------------------------------------------------------------
\begin{abstract}
\end{abstract}
%--------------------------------------------------------------------------------------------------
% Geoff
\section{Introduction}
\label{Introduction}

Automated Theorem Proving (ATP) is concerned with the development and use of tools that automate 
sound reasoning: the derivation of conclusions that follow inevitably from facts.
Automated Theorem Proving (ATP) is at the heart of many computational tasks, in particular for
verification \cite{Har06,HH19} and security \cite{Coo18}.\footnote{%
In AWS -
\href{https://aws.amazon.com/what-is/automated-reasoning/}{aws.amazon.com/what-is/automated-reasoning/}, 
\href{https://aws.amazon.com/security/provable-security//}{aws.amazon.com/security/provable-security/}.} 
New and emerging application areas include
chemistry \cite{Yad17}, 
biology \cite{CC+13}, 
medicine \cite{HLB05},
elections \cite{Nip09,BDS17}, 
auctions \cite{CK+15}, 
privacy \cite{Lib20},
law \cite{PS15}, 
ethics \cite{DF+16}, 
religion \cite{OZ11,BW14-ECAI,Hor19},
and business \cite{Han98}.
ATP systems are also used as components of more complex Artificial Intelligence (AI) systems,
and the impact of ATP is thus extended into many facets of society.
% in areas such as 
% knowledge representation \cite{TR+04}, 
% natural language processing \cite{BM05}, 
% planning \cite{NV07}, 
% agents \cite{TBP03}, 
% commonsense reasoning \cite{MS05}, 
% and the semantic web \cite{McG04}.

The Thousands of Problems for Theorem Provers (TPTP) World \cite{Sut24} is a well established 
infrastructure that supports research, development, and deployment of ATP systems.
The TPTP World includes 
the TPTP problem library \cite{Sut17},
the TSTP solution library \cite{Sut10},
standards for writing ATP problems and reporting ATP solutions \cite{SS+06,Sut08-KEAPPA},
tools and services for processing ATP problems and solutions \cite{Sut10},
and it supports the the annual CADE ATP System Competition (CASC) \cite{Sut16}.
Since its first release in 1993 the ATP community has used the TPTP World as an appropriate and 
convenient infrastructure for ATP system development, evaluation, and application.
The TPTP World has a diverse, engaged, and sustained user community, with various parts of the 
TPTP World being deployed in a range of applications in both academia and industry.\footnote{%
TPTP has contributed to recognized research in 627 publications that cite \cite{Sut17},
according to Google Scholar.}
The web page \href{https://www.tptp.org}{\tt www.tptp.org} provides access to all components.

The TPTP problem library was motivated by the need to provide support for meaningful ATP system 
evaluation.
This need was also (or became) evident in other logic solver communities, e.g., 
SAT~\cite{HS00-SATLIB} and SMT~\cite{BST10}.
For many years testing of logic solvers was done on individual developer's computers. 
In 2010 a proposal for centralised hardware and software support was developed,
and in 2011 a \$2.11 million NSF grant\footnote{%
NSF Awards 1058748 and 1058925, led by Aaron Stump and Cesare Tinelli at the University of Iowa} 
was obtained.
This grant led to the development and availability of StarExec Iowa~\cite{SST14} in 2012,
and a subsequent \$1.00 million grant\footnote{%
NSF Award 1730419} in 2017 expanded StarExec to Miami.
StarExec has been central to much progress in logic solvers over the last 10 years, supporting
16 logic solver communities, used for running many annual competitions~\cite{BB+19}, and 
supporting many many users.
StarExec Iowa provides community infrastructure for many logic solver communities,
e.g., ASP, QBF, SAT, SMT, Termination, etc, while
StarExec Miami is used by the TPTP community.
StarExec Miami has features that take advantage of TPTP standards, and is also used to host CASC.

It was recently announced that StarExec Iowa will be decommissioned. 
The maintainer of StarExec Iowa explained that ``the plan is to operate StarExec as usual for 
competitions Summer 2024 and Summer 2025, and then put the system into a read-only mode for one 
year (Summer 2025 to Summer 2026)''.
The 2017 grant for StarExec Miami paid for the hardware and three years of system administration.
The hardware is still hosted by the University of Miami High Performance Computing group,
funded on a shoe-string budget by the TPTP World.
While StarExec Miami will continue to operate while funding is available, it will not be able
to support the large number of logic solver communities that use the larger StarExec Iowa cluster.
In the long term StarExec will necessarily have to migrate to a commonly available compute service.
This paper describes work being done to containerize StarExec and ATP systems, so that they can 
be run on a broad range of computer platforms.
Additionally, this work aims to build a Kubernetes backend in StarExec so that Kubernetes can
be used to orchestrate distribute of StarExec job pairs over whatever compute nodes are available.
One possibility is to host StarExec-Kubernetes in AWS.

\paragraph{This paper is organized as follows:}

%--------------------------------------------------------------------------------------------------
% David
\section{Background}
\label{Background}

Containerization

Docker and Podman

Kubernetes

%--------------------------------------------------------------------------------------------------
% Jack and Geoff and David
\section{Containerizing StarExec and ATP Systems}
\label{Containerizing}

Base build is Ubuntu.
The {\tt artifacts} directory, where all relevant executables are copied when an ATP system
is executed, is created as part of this container.

{\tt dockerhub} for storing containers.
{\tt tptpstarexec} repository.
One directory for StarExec, one directory for each ATP system.

%--------------------------------------------------------------------------------------------------
% David
\subsection{StarExec}
\label{StarExec}

%--------------------------------------------------------------------------------------------------
% Geoff and Jack
\subsection{ATP Systems}
\label{ATPSystems}

The {\tt tptp-world-build} container provides utilities from the TPTP World \cite{Sut24} that 
are used by ATP systems, e.g., {\tt SPCForProblem} detects the Specialist Problem Class (SPC) 
\cite{SS01} of a problem that is used by some ATP systems to decide on what search parameters 
to use.
Additionally, the {\tt runsolver} utility \cite{Rou11} for limiting and reporting the resources
used by an ATP system is part of this container.
To support these utilities some libraries that are not part of the {\tt ubuntu-build} have
to be added before downloading and building the 
The {\tt /benchmark} directory, where the TPTP problem for the ATP system to solve is placed, is
created as part of this container.

A runnable ATP system container is built in two phases.
The ATP system executables are first put into an {\em ATP-system-name}{\tt-build} container,
which is subsequently put into a {\tt -runsolver} container that adds the {\tt runsolver} utility 
so that the resource usage of the ATP system can be limited and reported.

The {\em ATP-system-name}{\tt-build} container with the ATP system's executables is based on the
{\tt ubuntu-build} container.
The ATP system is retrieved online, e.g., from a GitHub repository, and the necessary commands
to build the executables are run.
The executables are copied into the {\tt /artifacts} directory.
The choice of which version of the ATP system to containerize is made inside the {\tt Dockerfile},
e.g., in Figure~\ref{E---build} {\tt E 3.0.03} is chosen.
This localization is necessary because the incantations for selecting an ATP system version vary 
from system to system.
By convention the container is named {\em ATP-system-name}{\tt -build}, and by default has
the {\tt :latest} tag,
Figure~\ref{E---build} shows the {\tt Dockerfile} for building E's {\tt -build} container, using 
the command {\tt podman build -t eprover-build .}.

\begin{figure}[htb]
{\small
\begin{verbatim}
#------------------------------------------------------------
FROM ubuntu-build

# Clones repository
ARG E_VERSION=E-3.0.03
RUN git clone --depth 1 --branch $E_VERSION https://github.com/eprover/eprover.git

# Set working directory to cloned sources directory
WORKDIR /eprover

# Builds first-order executable
RUN ./configure --bindir=/artifacts && \
    make && \
    make install
# RUN cp PROVER/eprover /artifacts/eprover

# Builds higher-order executable
RUN ./configure --enable-ho && \
    make rebuild
RUN cp PROVER/eprover-ho /artifacts/eprover-ho
#------------------------------------------------------------
\end{verbatim}
}
\caption{The {\tt Dockerfile} for E's {\tt -build} container}
\label{E---build}
\end{figure}

The ATP system's {\tt -runsolver} container adds {\tt runsolver} control to the 
{\em ATP-system-name}{\tt-build} container, so that when executed the resource usage of the
ATP system can be limited and reported.
The container is based on the {\em ATP-system-name}{\tt-build} and {\tt tptp-world-build}
containers.
Note how the container is built with the default {\tt :latest} tagged 
{\em ATP-system-name}{\tt-build}. 
The executables from the {\tt -runsolver} container are copied from its {\tt /artifacts}
directory into this container's {\tt /artifacts} directory.
Additionally, the {\tt run\_container} script, described in Section~\ref{Running}, is copied into
{\tt /artifacts}.
By convention this container is named
{\em ATP-system-name}{\tt :}{\em ATP-system-version}{\tt -runsolver}, i.e., including the version
number so that users know what version of the ATP system has been containerized.
Figure~\ref{E---runsolver} shows the {\tt Dockerfile} for building E's {\tt -runsolver}
container, using the command {\tt podman build -t eprover:3.0.03-runsolver .}, i.e., it contains
E version {\tt 3.0.03}.

\begin{figure}[htb]
{\small
\begin{verbatim}
#------------------------------------------------------------
FROM eprover-build AS builder
FROM tptp-world-build

ENV PATH=".:${PATH}"
WORKDIR /artifacts

# E-specific stuff from ostensibly external image
COPY --from=builder /artifacts/eprover /artifacts/
COPY --from=builder /artifacts/eprover-ho /artifacts/

# run_container script 
ADD run_container /artifacts/

# run_E script 
ADD run_E /artifacts/

ENTRYPOINT ["runsolver"]
#------------------------------------------------------------
\end{verbatim}
}
\caption{The {\tt Dockerfile} for E's {\tt -runsolver} container}
\label{E---runsolver}
\end{figure}

Each {\tt -runsolver} container is pushed to dockerhub in it's repository directory, tagged
as {\em ATP-system-name}{\tt :}{\em ATP-system-version}{\tt -runsolver-}{\em architecture},
where {\em architecture} is, e.g., {\tt arm64} or {\tt amd64}.

%--------------------------------------------------------------------------------------------------
% Geoff 
\subsection{Running ATP System Containers}
\label{Running}

\begin{figure}[htb]
{\footnotesize
\begin{verbatim}
#------------------------------------------------------------
#!/usr/bin/env python3

import argparse
import subprocess
import os, sys
import shutil


def getRunsolverArgs(args):
    mem_part = f" -M {args.memory_limit}" if args.memory_limit > 0 else ""
    return f"--timestamp --watcher-data /dev/null -C {args.cpu_limit} -W {args.wall_clock_limit}{mem_part}"


def getRunscriptArgs(args, args_format):
    parts = {
        'P': "/artifacts/CWD/benchmark",
        'C': args.cpu_limit,
        'W': args.wall_clock_limit,
        'I': args.intent,
        'M': args.memory_limit,
    }
    return ' '.join([str(parts[c.upper()]) for c in args_format])

def makeBenchmark(problem):
    if problem:
        shutil.copy(problem, "./benchmark")
    else:
        with open('./benchmark', 'w') as benchmark:
            benchmark.write(sys.stdin.read())


if __name__ == "__main__":
    parser = argparse.ArgumentParser("Wrapper for a podman call to a prover image")
    parser.add_argument("image_name", help="Image name, e.g., eprover:3.0.03-runsolver-arm64")
    parser.add_argument("-P", "--problem", help="Problem file if not stdin")
    parser.add_argument("--runscript", default="run_container PCWMI", help="System script and its args, e.g., 'run_E PWI'")
    parser.add_argument("-C", "--cpu-limit", default=60, type=int, help="Max CPU time in seconds")
    parser.add_argument("-W", "--wall-clock-limit", default=60, type=int, help="Max wall clock time in seconds")
    parser.add_argument("-M", "--memory-limit", default=-1, type=int, help="Max memory usage in MB")
    parser.add_argument("-I", "--intent", default="THM", choices=["THM", "SAT"], help="Intention (THM, SAT, etc)")
    parser.add_argument("--dry-run", action="store_true", help="dry run")
    args = parser.parse_args()

    # Format arguments
    runsolverArgs = getRunsolverArgs(args)
    runscript, runscriptArgsFormat = args.runscript.split()
    runscriptArgs = getRunscriptArgs(args, runscriptArgsFormat)

    # Construct podman command
    command = f"podman run -v .:/artifacts/CWD -t {args.image_name} {runsolverArgs} {runscript} {runscriptArgs}"

    # Run command or print for dry run
    if args.dry_run:
        print(command)
    else:
        makeBenchmark(args.problem)
        subprocess.run(command, shell=True)
        os.remove("./benchmark")
#------------------------------------------------------------
\end{verbatim}
}
\caption{The {\tt runsystem.py} script}
\label{runsystem.py}
\end{figure}
%--------------------------------------------------------------------------------------------------
% Geoff and David
\section{StarExec with Kubernetes}
\label{StarExecK}

Figure~\ref{AWSArchitecture} shows the architecture of the final implemented system.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.8\textwidth]{AWSArchitecture}
\caption{AWS architecture}
\label{AWSArchitecture}
\end{center}
\end{figure}

%--------------------------------------------------------------------------------------------------
% Geoff
\section{Conclusion}
\label{Conclusion}

This paper 
%--------------------------------------------------------------------------------------------------
\bibliographystyle{plain}
\bibliography{Bibliography.bib}
%--------------------------------------------------------------------------------------------------
\end{document}
%--------------------------------------------------------------------------------------------------
